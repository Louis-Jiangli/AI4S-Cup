{"cells":[{"cell_type":"code","execution_count":41,"id":"c2dbc405-9a00-436a-929c-7e6e00e3efdd","metadata":{},"outputs":[],"source":"import os\nimport pandas as pd \nimport numpy as np\nimport warnings\n# Suppress all warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(os.getcwd())\n# DATA_PATH = \"/bohr/PreEnzy-up6e/v1/data/\"\nDATA_PATH = \"/bohr/ai4s-06g0/v1/Enzyme_v1/data\"\nraw_data = pd.read_csv(f\"{DATA_PATH}/train.csv\") \ntest_data = pd.read_csv(f\"{DATA_PATH}/test.csv\") "},{"cell_type":"code","execution_count":42,"id":"7016207c","metadata":{},"source":"# Amino acids single-letter abbreviations ordered as in the image provided by the user\namino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n\n# Create a mapping from amino acid to index\naa_to_index = {aa: idx for idx, aa in enumerate(amino_acids)}\n\nmutation_positions = [42, 43, 73, 74, 101, 143, 148, 173, 176, 177, 182]","outputs":[]},{"cell_type":"code","execution_count":43,"id":"260c7436","metadata":{},"source":"# encode mutations into 1\ndef encode_mutation(mutation, updated_vector):\n    # extract information from the `mutation`\n    position = int(mutation[1:-1])\n    new_aa = mutation[-1]\n    \n    position_index = mutation_positions.index(position) * len(amino_acids)\n    amino_acid_index = aa_to_index[new_aa]\n    updated_vector[position_index + amino_acid_index] = 1\n    \n    return updated_vector\n\ndef encode_mutations(mutations, initialized_vector):\n    individual_mutations = mutations.split(';')\n    updated_vector = initialized_vector\n    for mutation in individual_mutations:\n        # WHY assign the updated vector by the initialized vecotor\n        # in each loop is also corrected here?\n        # updated_vector = initialized_vector\n        updated_vector = encode_mutation(mutation, updated_vector)\n    return updated_vector\n\ndef generate_matrix(data):\n    matrix = []\n    for line in data.index:\n        # Initialize the combined sparse vector for all mutations in the sequence\n        initialized_vector = np.zeros(len(amino_acids) * len(mutation_positions), dtype=int)\n        \n        mutations = data['Mutant'][line]\n        if mutations == \"WT\":\n            matrix.append(initialized_vector)\n            continue\n        \n        updated_vector = initialized_vector\n        updated_vector = encode_mutations(mutations, updated_vector)\n        matrix.append(updated_vector)\n    matrix = np.array(matrix)\n    return matrix","outputs":[]},{"cell_type":"code","execution_count":44,"id":"2901f4cd","metadata":{},"outputs":[],"source":"train_matrix = generate_matrix(raw_data)\ntest_matrix = generate_matrix(test_data)\ntrain_matrix.shape, test_matrix.shape\n# print(train_matrix[1])"},{"cell_type":"code","execution_count":45,"id":"e529c258","metadata":{},"source":"# weighted mutations\ndef encode_mutation(mutation, updated_vector, weights_dict):\n    # Extract information from the `mutation`\n    position = int(mutation[1:-1])\n    new_aa = mutation[-1]\n    \n    # Find the index for the mutation position\n    position_index = mutation_positions.index(position)\n    \n    # Find the index for the new amino acid\n    amino_acid_index = aa_to_index[new_aa]\n    \n    # Retrieve the weight for this mutation\n    weight = weights_dict[position][new_aa]\n    \n    # Update the vector with the weighted value\n    vector_index = position_index * len(amino_acids) + amino_acid_index\n    updated_vector[vector_index] = weight\n    # print(updated_vector)\n    return updated_vector\n\ndef encode_mutations(mutations, initialized_vector, weights_dict):\n    individual_mutations = mutations.split(';')\n    updated_vector = initialized_vector\n    for mutation in individual_mutations:\n        # WHY assign the updated vector by the initialized vecotor\n        # in each loop is also corrected here?\n        # updated_vector = initialized_vector\n        updated_vector = encode_mutation(mutation, updated_vector, weights_dict)\n    return updated_vector\n\ndef generate_matrix(data, weights_dict):\n    matrix = []\n    for line in data.index:\n        # Initialize the combined sparse vector for all mutations in the sequence\n        initialized_vector = np.zeros(len(amino_acids) * len(mutation_positions), dtype=float)\n        \n        mutations = data['Mutant'][line]\n        if mutations == \"WT\":\n            matrix.append(initialized_vector)\n            continue\n        \n        updated_vector = initialized_vector\n        updated_vector = encode_mutations(mutations, updated_vector, weights_dict)\n        matrix.append(updated_vector)\n    matrix = np.array(matrix)\n    return matrix","outputs":[]},{"cell_type":"code","execution_count":46,"id":"d3255476","metadata":{},"source":"# Load the ligandmpnn weight matrix\nweights_ligandmpnn_file = pd.read_csv(\"/bohr/ai4s-06g0/v1/Enzyme_v1/data/ligandmpnn.csv\", index_col=0)\n# print(weights_ligandmpnn_file)\n# weights_ligandmpnn = weights_ligandmpnn_file.to_numpy()\n# print(weights_ligandmpnn)\n\nweights_ligandmpnn = {}\n\n# Process each row in the DataFrame\nfor aa, row in weights_ligandmpnn_file.iterrows():\n    for position, score in row.items():\n        pos = int(position[1:])  # Extract the position as an integer\n        if pos not in weights_ligandmpnn:\n            weights_ligandmpnn[pos] = {}\n        weights_ligandmpnn[pos][aa] = score\n\n# print(weights_ligandmpnn)","outputs":[]},{"cell_type":"code","execution_count":47,"id":"7fa9602a-46c9-409a-8108-39939655bc63","metadata":{},"source":"! pip install openpyxl -i https://pypi.tuna.tsinghua.edu.cn/simple","outputs":[]},{"cell_type":"code","execution_count":48,"id":"202cc88b","metadata":{},"source":"# Load the ddG weight matrix\nfile_path = \"/bohr/ai4s-06g0/v1/Enzyme_v1/data/ddG_b_f.xlsx\"  # Update the file path to the actual file location\nweights_ddg_file = pd.read_excel(file_path, header=None)\n\nweights_ddg = {}\n\n# Process each row in the DataFrame\nfor index, row in weights_ddg_file.iterrows():\n    parts = row.dropna().tolist()  # Drop any NaN values and convert to list\n    # print(parts)\n    position = int(parts[0][1:])\n    # print(position)\n    original_residue = parts[0][0]\n    # print(original_residue)\n    \n    # Initialize the dictionary for this position if not already done\n    if position not in weights_ddg:\n        weights_ddg[position] = {}\n    \n    # Find the original residue's score\n    original_residue_index = parts.index(original_residue) + 1\n    original_residue_score = float(parts[original_residue_index])\n    \n    # Process the mutations and their weights\n    for i in range(1, len(parts), 2):\n        mutant = parts[i]\n        score = float(parts[i + 1])\n        corrected_score = score - original_residue_score\n        weights_ddg[position][mutant] = corrected_score\n\n# print(weights_ddg)","outputs":[]},{"cell_type":"code","execution_count":49,"id":"6ad626b2","metadata":{},"outputs":[],"source":"train_matrix_weighted_ligandmpnn = generate_matrix(raw_data, weights_ligandmpnn)\ntest_matrix_weighted_ligandmpnn = generate_matrix(test_data, weights_ligandmpnn)\ntrain_matrix_weighted_ligandmpnn.shape, test_matrix_weighted_ligandmpnn.shape\n# print(train_matrix_weighted_ligandmpnn[1])"},{"cell_type":"code","execution_count":50,"id":"391ba5e0","metadata":{},"outputs":[],"source":"train_matrix_weighted_ddg = generate_matrix(raw_data, weights_ddg)\ntest_matrix_weighted_ddg = generate_matrix(test_data, weights_ddg)\ntrain_matrix_weighted_ddg.shape, test_matrix_weighted_ddg.shape\n# print(train_matrix_weighted_ddg[1])"},{"cell_type":"code","execution_count":51,"id":"6331ac24","metadata":{},"source":"from sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.decomposition import PCA\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error\nfrom scipy.stats import spearmanr\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV, cross_val_predict\n! pip install xgboost -i https://pypi.tuna.tsinghua.edu.cn/simple\nfrom xgboost import XGBRegressor","outputs":[]},{"cell_type":"code","execution_count":52,"id":"0e6afb48","metadata":{},"source":"seed = 2024\nX = train_matrix_weighted_ddg\nX_test = test_matrix_weighted_ddg\nY_train_activity = raw_data['Activity']\nY_train_selectivity = raw_data['Selectivity']","outputs":[]},{"cell_type":"code","execution_count":53,"id":"9056dc09","metadata":{},"source":"ridge_grid = [\n    {\n        'model': [Ridge()],\n        'model__alpha': [0.1, 1.0, 10.0],\n        'model__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n        'model__tol': [1e-2, 1e-3],\n    }\n]\npls_grid = [\n    {\n        'model': [PLSRegression()],\n        'model__n_components': [2, 4, 6],\n        'model__scale': [True, False],\n        'model__max_iter': [1000],\n        'model__tol': [1e-2, 1e-3],\n    }\n]\n\nsvm_grid = [\n    {\n        'model': [SVR()],\n        'model__C' : [0.1, 1.0, 10.0],\n        'model__kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n        'model__degree' : [3],\n        'model__gamma': ['scale'],\n    }\n]\n\nrfr_grid = [\n    {\n        'model': [RandomForestRegressor()],\n        'model__n_estimators' : [20],\n        'model__criterion' : ['squared_error', 'absolute_error'],\n        'model__max_features': ['sqrt', 'log2'],\n        'model__min_samples_split' : [5, 10],\n        'model__min_samples_leaf': [1, 4]\n    }\n]\nxgb_grid= [\n    {\n        'model': [XGBRegressor()],\n        'model__learning_rate': [0.01, 0.1], \n        'model__n_estimators': [100, 200], \n        'model__max_depth': [3, 5], \n        'model__min_child_weight': [1, 3],  \n        'model__gamma': [0.0, 0.1], \n        'model__subsample': [0.8], \n        'model__colsample_bytree': [0.8], \n        'model__reg_alpha': [0.0],  \n        'model__reg_lambda': [0.1], \n        'model__nthread': [4], \n    }\n]","outputs":[]},{"cell_type":"code","execution_count":54,"id":"1d6526c6","metadata":{},"outputs":[],"source":"cls_list = [Ridge, PLSRegression, SVR, RandomForestRegressor, XGBRegressor]\nparam_grid_list = [ridge_grid, pls_grid, svm_grid, rfr_grid, xgb_grid]\n\npipe = Pipeline([\n    ('model', 'passthrough')\n])\n\ndef spearman_correlation(y_true, y_pred):\n    return spearmanr(y_true, y_pred)[0]\n\nspearman_scorer = make_scorer(spearman_correlation, greater_is_better=True)\n\n\ndef perform_grid_search(X_train, Y_train, score, cv = 10):\n    result_list = []\n    grid_list = []\n    for cls_name, param_grid in zip(cls_list, param_grid_list):\n        print(cls_name)\n        grid = GridSearchCV(\n            estimator = pipe,\n            param_grid = param_grid,\n            scoring = score,\n            verbose = 1,\n            n_jobs = -1,  # use all available cores\n            cv = cv\n        )\n        grid.fit(X_train, Y_train)\n        result_list.append(pd.DataFrame.from_dict(grid.cv_results_))\n        grid_list.append(grid)\n    return result_list, grid_list\n\nresult_list_activity, grid_list_activity = perform_grid_search(X, Y_train_activity, spearman_scorer)\nresult_list_selectivity, grid_list_selectivity = perform_grid_search(X, Y_train_selectivity, spearman_scorer)\n\ndef get_best_model(grid_list):\n    best_score = -np.inf\n    best_model = None\n    best_index = -1\n    for i, grid in enumerate(grid_list):\n        if grid.best_score_ > best_score:\n            best_score = grid.best_score_\n            best_model = grid.best_estimator_\n            best_index = i\n    return best_model, best_index\n\n# Get the best models for activity and selectivity\nbest_model_activity, best_index_activity = get_best_model(grid_list_activity)\nbest_model_selectivity, best_index_selectivity = get_best_model(grid_list_selectivity)\n\nprint(f\"Best model for activity is at index: {best_index_activity}, model: {type(best_model_activity.named_steps['model'])}\")\nprint(f\"Best model for selectivity is at index: {best_index_selectivity}, model: {type(best_model_selectivity.named_steps['model'])}\")"},{"cell_type":"code","execution_count":55,"id":"741a62b2-0eee-4c92-a172-befa8737ae15","metadata":{},"outputs":[],"source":"# Print the Spearman correlation score for the best models\ndef print_spearman_for_best_model(model, X, y, cv=10):\n    preds = cross_val_predict(model, X, y, cv=cv)\n    spearman_corr = spearmanr(y, preds)[0]\n    print(f\"Spearman correlation: {spearman_corr}\")\n\nprint(\"Spearman correlation for best model (Activity):\")\nprint_spearman_for_best_model(best_model_activity, X, Y_train_activity, cv=10)\n\nprint(\"Spearman correlation for best model (Selectivity):\")\nprint_spearman_for_best_model(best_model_selectivity, X, Y_train_selectivity, cv=10)"},{"cell_type":"code","execution_count":56,"id":"29f38f35","metadata":{},"source":"# Predict Activity and Selectivity on the test set\ntest_activity_predictions = best_model_activity.predict(X_test)\ntest_selectivity_predictions = best_model_selectivity.predict(X_test)\n\ntest_predictions_df = pd.DataFrame({\n    'Mutant': test_data['Mutant'],\n    'Activity': test_activity_predictions,\n    'Selectivity': test_selectivity_predictions\n})\ntest_predictions_df.to_csv(\"./submission.csv\", index=False) ","outputs":[]},{"cell_type":"code","execution_count":null,"id":"49f84667","metadata":{},"source":"","outputs":[]},{"cell_type":"code","execution_count":null,"id":"8551395b","metadata":{},"source":"","outputs":[]},{"cell_type":"code","execution_count":null,"id":"cd2d8f24","metadata":{},"source":"","outputs":[]},{"cell_type":"code","execution_count":null,"id":"672f5a57","metadata":{},"source":"","outputs":[]}],"metadata":{},"nbformat":4,"nbformat_minor":5}